{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1296.2962962962963,
  "global_step": 35000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 37.04,
      "learning_rate": 0.0002988888888888889,
      "loss": 0.6597,
      "step": 1000
    },
    {
      "epoch": 74.07,
      "learning_rate": 0.0002977777777777777,
      "loss": 0.4572,
      "step": 2000
    },
    {
      "epoch": 111.11,
      "learning_rate": 0.00029666666666666665,
      "loss": 0.3614,
      "step": 3000
    },
    {
      "epoch": 148.15,
      "learning_rate": 0.0002955555555555555,
      "loss": 0.3029,
      "step": 4000
    },
    {
      "epoch": 185.19,
      "learning_rate": 0.00029444444444444445,
      "loss": 0.2625,
      "step": 5000
    },
    {
      "epoch": 222.22,
      "learning_rate": 0.00029333333333333327,
      "loss": 0.2331,
      "step": 6000
    },
    {
      "epoch": 259.26,
      "learning_rate": 0.0002922222222222222,
      "loss": 0.2103,
      "step": 7000
    },
    {
      "epoch": 296.3,
      "learning_rate": 0.0002911111111111111,
      "loss": 0.1916,
      "step": 8000
    },
    {
      "epoch": 333.33,
      "learning_rate": 0.00029,
      "loss": 0.1774,
      "step": 9000
    },
    {
      "epoch": 370.37,
      "learning_rate": 0.0002888888888888888,
      "loss": 0.1653,
      "step": 10000
    },
    {
      "epoch": 407.41,
      "learning_rate": 0.00028777777777777775,
      "loss": 0.1546,
      "step": 11000
    },
    {
      "epoch": 444.44,
      "learning_rate": 0.0002866666666666667,
      "loss": 0.1456,
      "step": 12000
    },
    {
      "epoch": 481.48,
      "learning_rate": 0.00028555555555555555,
      "loss": 0.1374,
      "step": 13000
    },
    {
      "epoch": 518.52,
      "learning_rate": 0.0002844444444444444,
      "loss": 0.1309,
      "step": 14000
    },
    {
      "epoch": 555.56,
      "learning_rate": 0.0002833333333333333,
      "loss": 0.1253,
      "step": 15000
    },
    {
      "epoch": 592.59,
      "learning_rate": 0.00028222222222222223,
      "loss": 0.1194,
      "step": 16000
    },
    {
      "epoch": 629.63,
      "learning_rate": 0.0002811111111111111,
      "loss": 0.1152,
      "step": 17000
    },
    {
      "epoch": 666.67,
      "learning_rate": 0.00028,
      "loss": 0.1101,
      "step": 18000
    },
    {
      "epoch": 703.7,
      "learning_rate": 0.00027888888888888885,
      "loss": 0.1069,
      "step": 19000
    },
    {
      "epoch": 740.74,
      "learning_rate": 0.0002777777777777778,
      "loss": 0.1025,
      "step": 20000
    },
    {
      "epoch": 777.78,
      "learning_rate": 0.00027666666666666665,
      "loss": 0.0997,
      "step": 21000
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0002999378998870907,
      "loss": 0.667,
      "step": 22000
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0002999350771546857,
      "loss": 0.5874,
      "step": 23000
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00029993225442228076,
      "loss": 0.5594,
      "step": 24000
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0002999294316898758,
      "loss": 0.5435,
      "step": 25000
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0002999266089574708,
      "loss": 0.5275,
      "step": 26000
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00029992378622506585,
      "loss": 0.5158,
      "step": 27000
    },
    {
      "epoch": 1037.04,
      "learning_rate": 0.0002688888888888889,
      "loss": 0.2134,
      "step": 28000
    },
    {
      "epoch": 1074.07,
      "learning_rate": 0.00026777777777777775,
      "loss": 0.1297,
      "step": 29000
    },
    {
      "epoch": 1111.11,
      "learning_rate": 0.0002666666666666666,
      "loss": 0.1121,
      "step": 30000
    },
    {
      "epoch": 1148.15,
      "learning_rate": 0.00026555555555555555,
      "loss": 0.1032,
      "step": 31000
    },
    {
      "epoch": 1185.19,
      "learning_rate": 0.00026444444444444443,
      "loss": 0.0966,
      "step": 32000
    },
    {
      "epoch": 1222.22,
      "learning_rate": 0.0002633333333333333,
      "loss": 0.0926,
      "step": 33000
    },
    {
      "epoch": 1259.26,
      "learning_rate": 0.00026222222222222223,
      "loss": 0.0892,
      "step": 34000
    },
    {
      "epoch": 1296.3,
      "learning_rate": 0.0002611111111111111,
      "loss": 0.0859,
      "step": 35000
    }
  ],
  "max_steps": 270000,
  "num_train_epochs": 10000,
  "total_flos": 295401558720000.0,
  "trial_name": null,
  "trial_params": null
}
